# AIS-Solution-Intern
Data Analyst, Data science, Machine learning, power Bi, SQL,Statistics

Data cleaning, Visualization, Statistical analysis, Python, SQL ,PowerBi

Day 1-

i)	First thing we learned, how to download Anaconda software. We download software 

from anaconda.org and complete rest of process to run software. ii) We explore 

Anaconda software and learned new softwares from it, like R software, Jupiter 

Notebook, Jupiter Lab, etc. iii) In Jupiter notebook we learned how to create jupiter 

notebook and how to run it. By the end of the day we learned a lot of things that 

will benefit us a lot for this internship and we learned how to do coding in Jupiter 

notebook


Day2-

 Task 1:-
 
i) We learned Operators. Operators we have Arithmetic, Assignment, Comparison, 

Logical, Identity, Membership and etc.Looked at some of these types and learned how 

to use them. ii) After this we learned what is variable selection in python. We saw 

the different rules of how to create variables, how to write variable names.And also 

saw examples of variable selection. iii) Then we learned what Data Types are. There 

are two types of data types, Mutable Data Types and Immutable Data Types. 1) Mutable 

Data Types include List, Set, Dictionary Data Types. And saw examples of each. 2) 

Immutable Data Types include Numerical, String and Tuple Data Types and saw some 

examples.

     Day3-

Task 2:-

i) In Task 2 we saw some different conditions like if, if else, if elif, etc. In 

these conditions we have seen how their syntax works. And learned when and why to use 

these condition. ii)Learned what Loops are. And saw 2 types of loops, for loop and 

while loop. We understand when to use for loop and while loop, and how to use it.

Day4-

Task 3:-	

i) It was statement regarding. In it we learned what Break, Pass and Continue 

statement are and how they are used in for loop and while loop. And from the name we 

can understand that what will be their work. Break is used to break a loop, etc ii) 

After this we learned what statistical user defined function is. A function was 

created using statistical concept in it. Just created a function using its formula to 

find the mean. iii) Later learned what Logical user defined function is. Using this 

concept, a function was created after understanding the logic behind any concept or 

any formula.


Day5-

Task 4:-

NumPy Library: Basic, random(distributions and visualzation), universal functions

Day6-

Task 5:-

i) Pandas series creation and operationds. ii) Dataframe creation using matrix, 

dictionary and to red csv and xlsx files. iii) Dataframe operarions od dateframe 

methods in pandas. iv)Selection in dataframe: rows or columns selection, delete, 

update, index, remove inedx, etc. operations between two rowsor columns in dataframe. 

v) Missing values: checking for missing values, dropping missing values, fill missing 

values.

Day7-

Task 6:-

i) Matplotlib and Seaborn library for all type of ghraphical visualization. graphs 

like- Line, Scatter, Bar, Histogram, Box, Heatmap, Count, Regression, Area, Pie, etc.

Day8-

Task 7:-

Exercise on i) E-Commerce Purchase :- Solving given problems. ii) NumPy :- Exploring 

different functions of NumPy. iii) SF Salaries:- Solving given problems.

Day10-

Case Study 1:- Titanic Dataset

1.	read data and import necessary libraries data preprocessing :

2.	finding missing value and fill or drop

3.	if need drop variable

4.	label encoding for categorical variable

*Visualisation:

EDA: bar plot ,scatter plot, joint bar plot, Pai chart, etc

Model building:

5)choose dependent and independent variables 6) split data into train test ,80:20 

7)import naive bay’s algorithms 8) fit naive bays model on train data 9)predict text 

data using fitted model

*Model evaluation:


10.	find accuracy 11)find classification report 12)find confusion matrics

*Same process for : 13) knn algorithm 14) decision tree

*Comparison:

Naive bays ,knn, decision tree compair Accuracy,recall, precision

Day14-

Project :- "Box Office Revenue Prediction"

1.	read data and import necessary libraries data preprocessing :

2.	finding missing value and fill or drop

3.	if need drop variable

4.	label encoding for categorical variable

Day15-

*Visualisation:

used Power BI and make dashboard for better visulisation and make some different 

graohs for visulisation.


Day16-

Model Building:

Data has dependent variable is continues so we ues regressiion techqniues like

1.	Linear Regression

2.	KNN
3.	Decision Tree
4.	Random Forest
5.	Bagging
6.	Boosting
7.	SVR
8.	Nueral Network
9.	Voting
10.	Stacking

Day20-

*Model evaluation:

1)find accuracy

2)find regression report

3)find Root mean square eroor.

Day21-

*Same process for :

2.	KNN

3.	Decision Tree
4.	Random Forest

5.	Bagging

6.	Boosting

7.	SVR
8.	Nueral Network

9.	Voting
10.	Stacking

Day23-

*Comparison:


Root mean square eroor of KNN,Randaom forest,bagging,boosting,SVr,Nueral Network 
,Voting,Stacking.

Day24-

applied *Cross Validation:(Grid search CV) on all the algorithum to get best model 
for the data.

Day25-

Uesd Feature importance on data to get which feaure impact most on the traget 

variable.

Day-27

Fitted all above algorithm after feature importance.

*Comparison after feature importance:

•	Root mean square eroor of KNN,Randaom forest,bagging,boosting,SVr,Nueral Network 
,Voting,Stacking.

*applied Cross Validation after feature importance:(Grid search CV) on all the 

algorithum to get best model for the data.

*plot the camparsion graph of before and after feature importance and find which 

model is best fit for data.


Day28- PPT presentation.


